defaults:
  - base
  - callbacks: [early_stopping, model_checkpoint, model_summary, progress_bar, lr_monitor]
  - datamodule: marc_ja
  - logger: wandb
  - module: marc_ja
  - optimizer: adamw
  - scheduler: cosine_schedule_with_warmup
  - trainer: default
  - _self_

model_name_or_path: ku-nlp/deberta-v2-large-japanese
max_seq_length: 512
checkpoint_path: ""
limit_examples: -1

# set monitor and mode for early_stopping and model_checkpoint
monitor: valid/accuracy
mode: max

# hyper-parameters to be tuned
lr: 4e-5
max_epochs: 4
warmup_steps: null
warmup_ratio: 0.1
effective_batch_size: 256
